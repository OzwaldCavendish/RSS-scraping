{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating summed word2vec and doc2vec representations\n",
    "\n",
    "Uses data from every news dump created so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import torch\n",
    "import pickle\n",
    "import nltk\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from os import listdir\n",
    "from importlib import reload\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Doc2Vec\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ozzy/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/ozzy/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(article_text):\n",
    "    \"\"\" Utility function for cleaning up text for me.  There's probably better ways to prepare data. \"\"\"\n",
    "    article_text = re.sub(r'\\[[0-9]*\\]', ' ', article_text)  # Gets rid of numbers\n",
    "    article_text = re.sub(r'\\s+', ' ', article_text)         # Replaces all forms of white space with single space\n",
    "    #article_text = re.sub(r'\"', '', article_text)            # Removes quotation marks\n",
    "    \n",
    "    return(article_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the news corpus, clean and prepare sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_list = pd.read_csv(\"rss_urls.csv\").rename(columns={\"url\": \"source_url\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve a list of Json corpus files so far\n",
    "files = [x for x in listdir(\"./output\") if x.endswith(\".json\") and (\"corpus\" in x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all of the news corpus files\n",
    "articles = []\n",
    "for file in files:\n",
    "    with open(\"./output/\"+file, \"r\") as f:\n",
    "        dump = json.load(f)\n",
    "        articles = articles + list(dump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(data, source_list, how=\"left\", on=\"source_url\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['clean_text'] = data[['title', 'summary']].apply(lambda x: clean_text('. '.join(x)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15544, 8)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Robert Mueller: Charging Trump was not an opti...</td>\n",
       "      <td>[0.07501952, 0.008237855, 0.04390721, 0.004687...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nusrat Jahan Rafi: 16 charged in Bangladesh fo...</td>\n",
       "      <td>[0.011178329, 0.053766962, 0.08121284, 0.04253...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tankers almost certainly damaged by Iranian na...</td>\n",
       "      <td>[0.06743715, 0.08942383, 0.07022511, 0.0506297...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Huawei: US blacklist will harm billions of con...</td>\n",
       "      <td>[0.05050419, 0.03701058, 0.03597484, 0.0102925...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Growing crops in the shadow of Fukushima. Eigh...</td>\n",
       "      <td>[0.025309468, 0.06599146, 0.050482944, 0.0, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  \\\n",
       "0  Robert Mueller: Charging Trump was not an opti...   \n",
       "1  Nusrat Jahan Rafi: 16 charged in Bangladesh fo...   \n",
       "2  Tankers almost certainly damaged by Iranian na...   \n",
       "3  Huawei: US blacklist will harm billions of con...   \n",
       "4  Growing crops in the shadow of Fukushima. Eigh...   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [0.07501952, 0.008237855, 0.04390721, 0.004687...  \n",
       "1  [0.011178329, 0.053766962, 0.08121284, 0.04253...  \n",
       "2  [0.06743715, 0.08942383, 0.07022511, 0.0506297...  \n",
       "3  [0.05050419, 0.03701058, 0.03597484, 0.0102925...  \n",
       "4  [0.025309468, 0.06599146, 0.050482944, 0.0, 0....  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"./output/sentence_embeddings.pkl\", \"rb\") as f:\n",
    "    embeddings = pickle.load(f)\n",
    "\n",
    "embeddings_df = pd.DataFrame({\"clean_text\": list(embeddings.keys()),\n",
    "                              \"embeddings\": list(embeddings.values())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "      <th>retrieval_timestamp</th>\n",
       "      <th>source_url</th>\n",
       "      <th>summary</th>\n",
       "      <th>title</th>\n",
       "      <th>type</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wed, 29 May 2019 17:27:58 GMT</td>\n",
       "      <td>https://www.bbc.co.uk/news/world-us-canada-484...</td>\n",
       "      <td>2019-05-29 21:02:30.743862</td>\n",
       "      <td>http://feeds.bbci.co.uk/news/world/rss.xml</td>\n",
       "      <td>The special counsel said legal guidelines mean...</td>\n",
       "      <td>Robert Mueller: Charging Trump was not an option</td>\n",
       "      <td>world</td>\n",
       "      <td>Robert Mueller: Charging Trump was not an opti...</td>\n",
       "      <td>[0.07501952, 0.008237855, 0.04390721, 0.004687...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wed, 29 May 2019 14:45:39 GMT</td>\n",
       "      <td>https://www.bbc.co.uk/news/world-asia-48441604</td>\n",
       "      <td>2019-05-29 21:02:30.743862</td>\n",
       "      <td>http://feeds.bbci.co.uk/news/world/rss.xml</td>\n",
       "      <td>The schoolgirl was set on fire after filing a ...</td>\n",
       "      <td>Nusrat Jahan Rafi: 16 charged in Bangladesh fo...</td>\n",
       "      <td>world</td>\n",
       "      <td>Nusrat Jahan Rafi: 16 charged in Bangladesh fo...</td>\n",
       "      <td>[0.011178329, 0.053766962, 0.08121284, 0.04253...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wed, 29 May 2019 10:33:22 GMT</td>\n",
       "      <td>https://www.bbc.co.uk/news/world-middle-east-4...</td>\n",
       "      <td>2019-05-29 21:02:30.743862</td>\n",
       "      <td>http://feeds.bbci.co.uk/news/world/rss.xml</td>\n",
       "      <td>National Security Adviser John Bolton blames I...</td>\n",
       "      <td>Tankers almost certainly damaged by Iranian na...</td>\n",
       "      <td>world</td>\n",
       "      <td>Tankers almost certainly damaged by Iranian na...</td>\n",
       "      <td>[0.06743715, 0.08942383, 0.07022511, 0.0506297...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wed, 29 May 2019 07:49:20 GMT</td>\n",
       "      <td>https://www.bbc.co.uk/news/business-48441814</td>\n",
       "      <td>2019-05-29 21:02:30.743862</td>\n",
       "      <td>http://feeds.bbci.co.uk/news/world/rss.xml</td>\n",
       "      <td>Huawei says the US is \"using the strength of a...</td>\n",
       "      <td>Huawei: US blacklist will harm billions of con...</td>\n",
       "      <td>world</td>\n",
       "      <td>Huawei: US blacklist will harm billions of con...</td>\n",
       "      <td>[0.05050419, 0.03701058, 0.03597484, 0.0102925...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tue, 28 May 2019 23:02:53 GMT</td>\n",
       "      <td>https://www.bbc.co.uk/news/world-asia-48433222</td>\n",
       "      <td>2019-05-29 21:02:30.743862</td>\n",
       "      <td>http://feeds.bbci.co.uk/news/world/rss.xml</td>\n",
       "      <td>Eight years on from the nuclear disaster, some...</td>\n",
       "      <td>Growing crops in the shadow of Fukushima</td>\n",
       "      <td>world</td>\n",
       "      <td>Growing crops in the shadow of Fukushima. Eigh...</td>\n",
       "      <td>[0.025309468, 0.06599146, 0.050482944, 0.0, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            date  \\\n",
       "0  Wed, 29 May 2019 17:27:58 GMT   \n",
       "1  Wed, 29 May 2019 14:45:39 GMT   \n",
       "2  Wed, 29 May 2019 10:33:22 GMT   \n",
       "3  Wed, 29 May 2019 07:49:20 GMT   \n",
       "4  Tue, 28 May 2019 23:02:53 GMT   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://www.bbc.co.uk/news/world-us-canada-484...   \n",
       "1     https://www.bbc.co.uk/news/world-asia-48441604   \n",
       "2  https://www.bbc.co.uk/news/world-middle-east-4...   \n",
       "3       https://www.bbc.co.uk/news/business-48441814   \n",
       "4     https://www.bbc.co.uk/news/world-asia-48433222   \n",
       "\n",
       "          retrieval_timestamp                                  source_url  \\\n",
       "0  2019-05-29 21:02:30.743862  http://feeds.bbci.co.uk/news/world/rss.xml   \n",
       "1  2019-05-29 21:02:30.743862  http://feeds.bbci.co.uk/news/world/rss.xml   \n",
       "2  2019-05-29 21:02:30.743862  http://feeds.bbci.co.uk/news/world/rss.xml   \n",
       "3  2019-05-29 21:02:30.743862  http://feeds.bbci.co.uk/news/world/rss.xml   \n",
       "4  2019-05-29 21:02:30.743862  http://feeds.bbci.co.uk/news/world/rss.xml   \n",
       "\n",
       "                                             summary  \\\n",
       "0  The special counsel said legal guidelines mean...   \n",
       "1  The schoolgirl was set on fire after filing a ...   \n",
       "2  National Security Adviser John Bolton blames I...   \n",
       "3  Huawei says the US is \"using the strength of a...   \n",
       "4  Eight years on from the nuclear disaster, some...   \n",
       "\n",
       "                                               title   type  \\\n",
       "0   Robert Mueller: Charging Trump was not an option  world   \n",
       "1  Nusrat Jahan Rafi: 16 charged in Bangladesh fo...  world   \n",
       "2  Tankers almost certainly damaged by Iranian na...  world   \n",
       "3  Huawei: US blacklist will harm billions of con...  world   \n",
       "4           Growing crops in the shadow of Fukushima  world   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0  Robert Mueller: Charging Trump was not an opti...   \n",
       "1  Nusrat Jahan Rafi: 16 charged in Bangladesh fo...   \n",
       "2  Tankers almost certainly damaged by Iranian na...   \n",
       "3  Huawei: US blacklist will harm billions of con...   \n",
       "4  Growing crops in the shadow of Fukushima. Eigh...   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [0.07501952, 0.008237855, 0.04390721, 0.004687...  \n",
       "1  [0.011178329, 0.053766962, 0.08121284, 0.04253...  \n",
       "2  [0.06743715, 0.08942383, 0.07022511, 0.0506297...  \n",
       "3  [0.05050419, 0.03701058, 0.03597484, 0.0102925...  \n",
       "4  [0.025309468, 0.06599146, 0.050482944, 0.0, 0....  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.merge(data, embeddings_df, how=\"left\", on=\"clean_text\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment with interesting story extraction!\n",
    "\n",
    "In this case we try to extract interesting stories by using cosine similarity and the page rank algorithm to find stories least similar to those in the sensible \"world\" RSS feeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the \"average\" array for \"world\" stories\n",
    "world_array = np.mean(np.asarray(list( data[data['type']==\"world\"]['embeddings'].drop_duplicates() )), axis=0).reshape(1, -1)\n",
    "\n",
    "data['world_similarity'] = data['embeddings'].apply(lambda x: cosine_similarity(world_array, x.reshape(1, -1))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['clean_text', 'world_similarity']].sort_values(\"world_similarity\", ascending=True).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"temp_cosine_results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
